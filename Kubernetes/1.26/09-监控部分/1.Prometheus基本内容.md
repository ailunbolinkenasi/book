# Prometheus

我们知道监控是保证系统运行必不可少的功能，特别是对于 Kubernetes 这种比较庞大的系统来说，监控报警更是不可或缺，我们需要时刻了解系统的各种运行指标，也需要时刻了解我们的 Pod 的各种指标，更需要在出现问题的时候有报警信息通知到我们。

在早期的版本中 Kubernetes 提供了 heapster、influxDB、grafana 的组合来监控系统，在现在的版本中已经移除掉了 heapster，现在更加流行的监控工具是 [Prometheus](https://prometheus.io/)，Prometheus 是 Google 内部监控报警系统的开源版本，是 Google SRE 思想在其内部不断完善的产物，它的存在是为了更快和高效的发现问题，快速的接入速度，简单灵活的配置都很好的解决了这一切，而且是已经毕业的 CNCF 项目。

## 简介

Prometheus 最初是 SoundCloud 构建的开源系统监控和报警工具，是一个独立的开源项目，于2016年加入了 CNCF 基金会，作为继 Kubernetes 之后的第二个托管项目。Prometheus 相比于其他传统监控工具主要有以下几个特点：

- 具有由 metric 名称和键/值对标识的时间序列数据的多维数据模型
- 有一个灵活的查询语言
- 不依赖分布式存储，只和本地磁盘有关
- 通过 HTTP 的服务拉取时间序列数据
- 也支持推送的方式来添加时间序列数据
- 还支持通过服务发现或静态配置发现目标
- 多种图形和仪表板支持

Prometheus 由多个组件组成，但是其中有些组件是可选的：

- `Prometheus Server`：用于抓取指标、存储时间序列数据
- `exporter`：暴露指标让任务来抓
- `pushgateway`：push 的方式将指标数据推送到该网关
- `alertmanager`：处理报警的报警组件 `adhoc`：用于数据查询

大多数 Prometheus 组件都是用 Go 编写的，因此很容易构建和部署为静态的二进制文件。下图是 Prometheus 官方提供的架构及其一些相关的生态系统组件：

![Prometheus架构图](https://bxdc-static.oss-cn-beijing.aliyuncs.com/images/20220402181610.png)

## 安装

由于 Prometheus 是 Golang 编写的程序，所以要安装的话也非常简单，只需要将二进制文件下载下来直接执行即可

- 前往地址：https://prometheus.io/download 下载最新版本即可。

Prometheus 是通过一个 YAML 配置文件来进行启动的，如果我们使用二进制的方式来启动的话，可以使用下面的命令：

```shell
./prometheus --config.file=prometheus.yml
```



其中 `prometheus.yml` 文件的基本配置如下：

```yaml
global:
  scrape_interval:     15s
  evaluation_interval: 15s

rule_files:
  # - "first.rules"
  # - "second.rules"

scrape_configs:
  - job_name: prometheus
    static_configs:
      - targets: ['localhost:9090']
```



上面这个配置文件中包含了3个模块：`global`、`rule_files` 和 `scrape_configs`。

- `global` 模块控制 `Prometheus Server` 的全局配置：
  - `scrape_interval`：表示 prometheus 抓取指标数据的频率，默认是15s，我们可以覆盖这个值
  - `evaluation_interval`：用来控制评估规则的频率，prometheus 使用规则产生新的时间序列数据或者产生警报
- `rule_files`：指定了报警规则所在的位置，prometheus 可以根据这个配置加载规则，用于生成新的时间序列数据或者报警信息，当前我们没有配置任何报警规则。
- `scrape_configs` 用于控制 prometheus 监控哪些资源。

由于 prometheus 通过 HTTP 的方式来暴露的它本身的监控数据，prometheus 也能够监控本身的健康情况。在默认的配置里有一个单独的 job，叫做 prometheus，它采集 prometheus 服务本身的时间序列数据。这个 job 包含了一个单独的、静态配置的目标：监听 localhost 上的 9090 端口。prometheus 默认会通过目标的 `/metrics` 路径采集 metrics。所以，默认的 job 通过 URL：`http://localhost:9090/metrics` 采集 metrics。收集到的时间序列包含 prometheus 服务本身的状态和性能。如果我们还有其他的资源需要监控的话，直接配置在 `scrape_configs` 模块下面就可以了。

### 示例应用

比如我们在本地启动一些样例来让 Prometheus 采集。Go 客户端库包含一个示例，该示例为具有不同延迟分布的三个服务暴露 RPC 延迟。

首先确保已经安装了 Go 环境并启用 go modules，下载 Prometheus 的 Go 客户端库并运行这三个示例：

```shell
git clone https://github.com/prometheus/client_golang.git
cd client_golang/examples/random
export GO111MODULE=on
export GOPROXY=https://goproxy.cn
go build
```

然后在3个独立的终端里面运行3个服务：

```shell
./random -listen-address=:8080
./random -listen-address=:8081
./random -listen-address=:8082
```

这个时候我们可以得到3个不同的监控接口：

- http://localhost:8080/metrics

- http://localhost:8081/metrics 

- http://localhost:8082/metrics

然后可以修改`prometheus.yml`来设置刚刚我们启动的几个监控端口

```yaml
scrape_configs:
  - job_name: 'example-random'
    # Override the global default and scrape targets from this job every 5 seconds.
    scrape_interval: 5s
    static_configs:
      - targets: ['localhost:8080', 'localhost:8081']
        labels:
          group: 'production'
      - targets: ['localhost:8082']
        labels:
          group: 'canary'
```

为了能够方便的管理配置文件，我们这里将 `prometheus.yml` 文件用 ConfigMap 的形式进行管理：

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      scrape_timeout: 15s
    scrape_configs:
    - job_name: 'prometheus'
      static_configs:
      - targets: ['localhost:9090']
```

配置文件创建完成了，以后如果我们有新的资源需要被监控，我们只需要将上面的 ConfigMap 对象更新即可。现在我们来创建 prometheus 的 Pod 资源，按理说正常会用`StatefulSet`进行部署

- 有需要了解`nfs-client-provisioner`：[Github](https://github.com/kubernetes-sigs/nfs-subdir-external-provisioner)

> 注意：这里我们用了`nfs-client-provisioner`来动态的分配`Pv`以及`Pvc`存储来持久化数据卷。

```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: prometheus-k8s
  labels:
    app: prometheus-k8s
spec:
  serviceName: prometheus
  replicas: 2
  selector:
    matchLabels:
      app: prometheus-k8s
  template:
    metadata:
      labels:
        app: prometheus-k8s
    spec:
      containers:
      - name: prometheus-k8s
        image: prom/prometheus:v2.30.3
        args:
        - "--config.file=/etc/prometheus/prometheus.yml"
        - "--storage.tsdb.path=/data" # 指定Tsdb的数据存储目录
        - '--web.console.templates=/etc/prometheus/consoles' 
        - '--web.console.libraries=/etc/prometheus/console_libraries'
        - '--storage.tsdb.retention.time=7d'
        - '--web.enable-lifecycle' # 支持热更新
        - '--query.max-concurrency=1000'
        - '--web.route-prefix=/'
        ports:
          - name: web
            containerPort: 9090
            protocol: TCP
        volumeMounts:
        - name: prometheus-config
          mountPath: /etc/prometheus
        - name: prometheus-data
          mountPath: /data
        resources:
          requests:
            cpu: 100m
            memory: 512Mi
          limits:
            cpu: 100m
            memory: 512Mi
      volumes:
      - name: prometheus-config
        configMap:
          name: prometheus-config
  volumeClaimTemplates:
    - metadata:
        name: prometheus-data
        annotations:
          volume.beta.kubernetes.io/storage-class: "managed-nfs-storage"
      spec:
        accessModes: ["ReadWriteMany"]
        resources:
          requests:
            storage: 20Gi
---
apiVersion: v1
kind: ConfigMap
metadata: 
  name: prometheus-config
  labels:
    app: prometheus
data:
  prometheus.yaml: |
    global:
      scrape_interval: 15s
      scrape_timeout: 15s
    scrape_configs:
    - job_name: 'prometheus'
      static_configs:
      - targets: ['localhost:9090']
---
apiVersion: v1
kind: Service
metadata:
  name: prometheus
spec:
  selector:
    app: prometheus-k8s
  ports:
  - name: http
    port: 9090
    targetPort: 9090
  clusterIP: None
```

## 监控一些Kubernetes的应用

Prometheus 的数据指标是通过一个公开的 HTTP(S) 数据接口获取到的，我们不需要单独安装监控的 agent，只需要暴露一个 metrics 接口，Prometheus 就会定期去拉取数据；对于一些普通的 HTTP 服务，我们完全可以直接重用这个服务，添加一个 `/metrics` 接口暴露给 Prometheus；而且获取到的指标数据格式是非常易懂的，不需要太高的学习成本。

现在很多服务从一开始就内置了一个 `/metrics` 接口，比如 Kubernetes 的各个组件、istio 服务网格都直接提供了数据指标接口。有一些服务即使没有原生集成该接口，也完全可以使用一些 `exporter` 来获取到指标数据，比如 `mysqld_exporter`、`node_exporter`，这些 `exporter` 就有点类似于传统监控服务中的 agent，作为服务一直存在，用来收集目标服务的指标数据然后直接暴露给 Prometheus。

### 普通应用

对于普通应用只需要能够提供一个满足 prometheus 格式要求的 `/metrics` 接口就可以让 Prometheus 来接管监控，比如 Kubernetes 集群中非常重要的 CoreDNS 插件，一般默认情况下就开启了 `/metrics` 接口：

```bash
[root@Online-Beijing-master1 ~]# kubectl get cm coredns -n kube-system -o yaml
```

```yaml
apiVersion: v1
data:
  Corefile: |
    .:53 {
        errors
        health {
           lameduck 5s
        }
        ready
        kubernetes cluster.local in-addr.arpa ip6.arpa {
           pods insecure
           fallthrough in-addr.arpa ip6.arpa
           ttl 30
        }
        prometheus :9153  # 默认开启了Prometheus
        forward . /etc/resolv.conf {
           max_concurrent 1000
        }
        template ANY AAAA {
           rcode NXDOMAIN
        }
        cache 30
        loop
        reload
        loadbalance
    }
```

基于这种情况我们可以直接配置`configmap`,因为支持热更新

- 以`volume`挂载方式进行的配置文件会支持热更新,但是具体应用是否取决于热更新要取决于应用
- 如果需要热更新请了解`Prometheus-Reload`

```yaml
global:
  scrape_interval: 15s
  scrape_timeout: 15s
scrape_configs:
- job_name: 'prometheus'
  static_configs:
  - targets: ['localhost:9090']
- job_name: 'CoreDns'
  static_configs:
  - targets: ['10.10.180.70:9153'] 
```

### 使用exporter监控

- 关于更多地`exporter`请前往：[PrometheusExporter](https://prometheus.io/docs/instrumenting/exporters/)

上面我们也说过有一些应用可能没有自带 `/metrics` 接口供 Prometheus 使用，在这种情况下，我们就需要利用 `exporter` 服务来为 Prometheus 提供指标数据了。Prometheus 官方为许多应用就提供了对应的 `exporter` 应用，也有许多第三方的实现，我们可以前往官方网站进行查看：[exporters](https://prometheus.io/docs/instrumenting/exporters/)，当然如果你的应用本身也没有 exporter 实现，那么就要我们自己想办法去实现一个 `/metrics` 接口了，只要你能提供一个合法的 `/metrics` 接口，Prometheus 就可以监控你的应用。

比如我们这里通过一个 [nginx-exporter](https://github.com/nginxinc/nginx-prometheus-exporter) 的服务来监控 redis 服务，对于这类应用，我们一般会以 `sidecar` 的形式和主应用部署在同一个 Pod 中，比如我们这里来部署一个nginx 应用，并用 nginx-exporter 的方式来采集监控数据供 Prometheus 使用，如下资源清单文件：

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-work
  labels:
    app: nginx-work
spec:
  selector:
    matchLabels:
      app: nginx-work
  template:
    metadata:
      labels:
        app: nginx-work
    spec:
      containers:
      - name: nginx-work
        image: nginx:latest
        resources:
          requests:
            cpu: 10m
            memory: 200Mi
        ports:
          - name: http
            containerPort: 80
        volumeMounts:
          - name: nginx-config
            mountPath: /etc/nginx/conf.d
      - name: nginx-exporter-sidecar
        image: nginx/nginx-prometheus-exporter:0.10.0
        args:
        - '--nginx.scrape-uri=http://10.10.244.252/nginx_status'
        resources:
          requests:
            memory: 25Mi
        ports:
          - name: prom-http
            containerPort: 9113
      volumes:
      - name: nginx-config
        configMap:
          name: nginx-config
---
apiVersion: v1
kind: Service
metadata:
  name: nginx-web
  labels:
    app: nginx-work
spec:
  selector:
    app: nginx-work
  ports:
  - name: nginx
    port: 80
    targetPort: 80
  - name: prom-http
    port: 9113
    targetPort: 9113
  - name: status
    port: 8080
    targetPort: 8080
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: nginx-config
data:
  default.conf: |
    server {
      listen       80;
      server_name  localhost;

      location / {
        root   /usr/share/nginx/html;
        index  index.html index.htm;
      }
      location /nginx_status {
        stub_status on;
      }
    }

```

同样的我们现在只需要更新`prometheus`的`config`文件即可

```yaml
- job_name: 'nginx'
  static_configs:
  - targets: ['nginx-web:9113']
```

